{
 "metadata": {
  "name": "",
  "signature": "sha256:804a7a29e9a134cc352c48375dc58ff94b106704a8cd9d802d1a08ac7990f052"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "\n",
      "This script scrapes information about harrassment at the Nigerian 2015 elections from www.reclamnaija.com \n",
      "Written by : Jasper Ginn \n",
      "Date : 25-01-2015\n",
      "Last modified : 07-02-2015\n",
      "Please send suggestions/comments to : Jasperginn@hotmail.com \n",
      "\n",
      "'''\n",
      "\n",
      "# --------------------------------------------------------------------------------\n",
      "\n",
      "'''\n",
      "Import modules\n",
      "'''\n",
      "\n",
      "# Import os\n",
      "import os\n",
      "# BeautifulSoup\n",
      "from bs4 import BeautifulSoup\n",
      "# Logging\n",
      "import logging\n",
      "# requests\n",
      "import requests\n",
      "# Import SQLite\n",
      "import sqlite3 as lite\n",
      "# Import regex\n",
      "import re\n",
      "# Import datetime\n",
      "import datetime\n",
      "# Import os.path (to check if db exists)\n",
      "import os.path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "+++ MAIN FUNCTIONS +++\n",
      "'''\n",
      "\n",
      "'''\n",
      "FUNCTION 1 : function that captures the index of all urls on each page\n",
      "    parameters : \n",
      "        url  :  string\n",
      "            url of the index page.\n",
      "'''\n",
      "\n",
      "def naijaIndex(url):\n",
      "    page = requests.get(url).text\n",
      "    soup = BeautifulSoup(page, \"html.parser\")\n",
      "    # Identify the table which holds the values of interest.\n",
      "    # Identify the table which holds the values of interest.\n",
      "    table = soup.find('div',{'class':'rb_list-and-map-box table-responsive'})\n",
      "    # isolate reports\n",
      "    tabsun = table.findAll('div', {'class' : 'rb_report unverified'})\n",
      "    tabsve = table.findAll('div', {'class' : 'rb_report verified'})\n",
      "    tabs = tabsun + tabsve\n",
      "    urls = [ N.find('a').get('href')\n",
      "             for N in tabs ]\n",
      "    # Return\n",
      "    return(urls)\n",
      "        \n",
      "'''\n",
      "FUNCTION 2 : Function that scrapes results from each individual page and stores it in the database\n",
      "    parameters : \n",
      "        url  :  string\n",
      "            url pointing towards the individual report\n",
      "'''\n",
      "\n",
      "def naijaReport(url):\n",
      "    soup = BeautifulSoup(requests.get(url).text)\n",
      "    # Lon / Lat\n",
      "    try:\n",
      "        geo = naijaLocs(soup)\n",
      "        lon = geo[0]\n",
      "        lat = geo[1]\n",
      "    except:\n",
      "        print(\"GEO: There occurred an error while extracting the geolocations for url {}. This isn't absolutely necessary, and the rest of the data should still be collected!\".format(url))\n",
      "        lon = \"\"\n",
      "        lat = \"\"\n",
      "    try:\n",
      "        # report\n",
      "        text = ' '.join(soup.find('div',{'class':'report-description'}).find('div',{'class':'content'}).contents[0].split())\n",
      "    except: \n",
      "        print(\"COMPLAINT: There occurred an error while scraping the report for url {}.\".format(url))\n",
      "        text = \"\"\n",
      "    try:\n",
      "        # Details\n",
      "        text = ' '.join(soup.find('div',{'class':'report-description'}).find('div',{'class':'content'}).contents[0].split())\n",
      "        reportD = soup.find('div',{'class':'report-details'})\n",
      "        # Verified?\n",
      "        ver = reportD.find('div',{'class':'verified'}).text\n",
      "        # tag\n",
      "        tag = reportD.find('h1').text\n",
      "        # Details\n",
      "        det = reportD.find('ul',{'class':'details'}).findAll('li')\n",
      "        Loc = ' '.join(det[0].contents[2].split())\n",
      "        Dat = datetime.datetime.strptime(' '.join(det[1].contents[2].split()),'%b %d %Y').date()\n",
      "        Tim = ' '.join(det[2].contents[2].split())\n",
      "        Cat = ' '.join(det[3].find('a').text.split())\n",
      "        scrapedate = datetime.date.today()\n",
      "    except:\n",
      "        print 'DETAILS: There occurred an error while scraping the details for url {}.'.format(url)\n",
      "        ver = \"\"\n",
      "        tag = \"\"\n",
      "        Loc = \"\"\n",
      "        Dat = \"\"\n",
      "        Tim = \"\"\n",
      "        Cat = \"\"\n",
      "        scrapedate = datetime.date.today()\n",
      "    # Insert values in db\n",
      "    vals = [ ( url ,\n",
      "             str(Dat) ,\n",
      "             Loc ,\n",
      "             lon ,\n",
      "             lat ,\n",
      "             tag , \n",
      "             text ,\n",
      "             ver ,\n",
      "             Cat ,\n",
      "             str(Tim) ,\n",
      "             str(scrapedate) ) ]\n",
      "    # Return\n",
      "    return(vals)\n",
      "\n",
      "'''\n",
      "+++ HELPER FUNCTIONS +++\n",
      "'''\n",
      "\n",
      "'''\n",
      "FUNCTION 3 : create the URLs for the scraper\n",
      "    Parameters : \n",
      "        lower_range : integer\n",
      "            Low end of the page number (lower == more recent). Should be set at 1\n",
      "        upper_range : integer\n",
      "            High end of the page number (higher == less recent).\n",
      "'''\n",
      "\n",
      "def naijaPages(lower_range, upper_range):\n",
      "    pages = range(lower_range,upper_range)\n",
      "    urls = [ 'http://reclaimnaija.net/reports?page={}'.format(str(p)) \n",
      "             for p in pages ]\n",
      "    return(urls)\n",
      "\n",
      "'''\n",
      "FUNCTION 4 : create the SQLite database and commit headers\n",
      "    Parameters :\n",
      "        dbname    : string\n",
      "            name of the database\n",
      "        tablename : string\n",
      "            name of the table in which to store results\n",
      "        path  : string\n",
      "            path to store database. Defaults to '/home/vagrant/Documents/'\n",
      "'''\n",
      "\n",
      "def naijadbSetup(dbname, tablename, path = '~/desktop', override = \"TRUE\"):\n",
      "    # Want to replace the database?\n",
      "    if override == 'TRUE':\n",
      "        pathfile = naijaPathmaker(dbname, path)\n",
      "        con = lite.connect(pathfile)\n",
      "        cur = con.cursor()\n",
      "        # send headers and create table\n",
      "        cur.execute(\"DROP TABLE IF EXISTS {};\".format(tablename))\n",
      "        cur.execute(\"CREATE TABLE {}(URL TEXT, Date TEXT, Location TEXT, Longitude REAL, Latitude REAL, Title TEXT, Report TEXT, Verified TEXT, Category TEXT, Time TEXT, Scrapedate TEXT)\".format(tablename))\n",
      "        # Commit\n",
      "        con.commit()\n",
      "    else:\n",
      "        print \"A database with the name {} already exists for path {}. You specified the override option to be {}. The database will be left alone . . . yay!\".format(dbname, path, str(override))\n",
      "\n",
      "'''\n",
      "FUNCTION 5 : Insert results form each page to the database\n",
      "    Parameters :\n",
      "        values_list : list \n",
      "            list of values to send to the database\n",
      "        dbname      : string\n",
      "            name of the database\n",
      "        tablename   : string\n",
      "            name of the table in which to store results\n",
      "        path        : string\n",
      "            path to the database. Defaults to '/home/vagrant/Documents/'\n",
      "'''\n",
      "\n",
      "def naijadbInsert(values_list, dbname, tablename , path = '~/desktop/'):\n",
      "    pathfile = naijaPathmaker(dbname, path)\n",
      "    try:\n",
      "        con = lite.connect(pathfile) \n",
      "        with con:  \n",
      "            # Cursor file\n",
      "            cur = con.cursor()\n",
      "            # Write values to db\n",
      "            cur.executemany(\"INSERT INTO {} (URL, Date, Location, Longitude, Latitude, Title, Report, Verified, Category, Time , Scrapedate) VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?);\".format(tablename), values_list)\n",
      "            # Commit (i.e. save) changes\n",
      "            con.commit()\n",
      "        # Close connection\n",
      "        con.close()           \n",
      "    except:\n",
      "        print 'Error while setting up the database. Quitting the script now . . . '\n",
      "        \n",
      "'''\n",
      "FUNCTION 7 : Helper function to retrieve longitude and latitude \n",
      "    parameters :\n",
      "        soup_object  :  A BeautifulSoup instance\n",
      "            Soup object from the report url\n",
      "'''\n",
      "\n",
      "def naijaLocs(soup_object):\n",
      "    # Found the Lon/Lat combination. Not pretty, but oh well . . . \n",
      "    lonlat = re.findall('var myPoint = new OpenLayers.LonLat[(\\d)., ]*', string = soup_object.text)[0].strip('var myPoint = new OpenLayers.LonLat')\n",
      "    lon = lonlat.split(',')[0].strip('( ')\n",
      "    lat = lonlat.split(',')[1].strip(' )')\n",
      "    return(float(lon), float(lat))\n",
      "\n",
      "'''\n",
      "FUNCTION 8 : Helper function to check if the database already exists. If exists, then don't make a new one (unless you specified to overwrite the database)\n",
      "    parameters :\n",
      "        path : string\n",
      "            path to the database\n",
      "        tablename : string\n",
      "            name of the SQLite database\n",
      "        \n",
      "'''\n",
      "\n",
      "def naijadbExists(path, dbname):\n",
      "    if path.endswith('/'):\n",
      "        ret = os.path.isfile(path + dbname) \n",
      "        return(ret)\n",
      "    else:\n",
      "        ret = os.path.isfile(path + '/' + dbname)\n",
      "        return(ret)\n",
      "    \n",
      "'''\n",
      "FUNCTION 9 : Helper function to check whether a report already exists in the database. Here, we are checking the specific report URL\n",
      "(which is basically a unique ID) against all report URLs that already exist in the db.\n",
      "    parameters : \n",
      "        url : string\n",
      "            url of the specific report at reclaimnaija\n",
      "        dbname : string\n",
      "            name of the database\n",
      "        dbtable : string\n",
      "            table in which reclaimnaija results are stored\n",
      "        path : string\n",
      "            system path where the database is stored. Defaults to '~/desktop'\n",
      "'''\n",
      "\n",
      "def naijadbCheck(url, dbname, dbtable, path = '~/desktop/'):\n",
      "    pathsal = naijaPathmaker(dbname, path)\n",
      "    con = lite.connect(pathsal)\n",
      "    # Cursor file\n",
      "    with con:\n",
      "        cur = con.cursor()\n",
      "        cur.execute(\"SELECT URL FROM {} WHERE URL = ?\".format(dbtable), (url,))\n",
      "        data=cur.fetchone()\n",
      "        if data is None:\n",
      "            return(None)\n",
      "        else:\n",
      "            print('Report for url {} already in database . . . moving on'.format(url))\n",
      "            return(data[0])\n",
      "    # Close db connection\n",
      "    con.close()\n",
      "    \n",
      "'''\n",
      "FUNCTION 10 : Helper function that creates the path for the database. It evaluates whether the path specified by the user ends with\n",
      "'/'. If yes, then paste. If no, then add the '/' to avoid problems.\n",
      "    parameters :\n",
      "        dbname : string\n",
      "            name of the database\n",
      "        path : string\n",
      "            system path where the database is stored. Defaults to '~/desktop'\n",
      "'''\n",
      "\n",
      "def naijaPathmaker(dbname, path):\n",
      "    if path.endswith('/'):\n",
      "        return(path + dbname + '.db')\n",
      "    else:\n",
      "        return(path + '/' + dbname + '.db')\n",
      "\n",
      "'''\n",
      "+++ MAIN +++\n",
      "'''\n",
      "\n",
      "def main(lower_range, upper_range, dbname, tablename, path = \"~/desktop/\", override = 'FALSE'):\n",
      "    \n",
      "    '''\n",
      "    Set up logger\n",
      "    '''\n",
      "    \n",
      "    # Log name\n",
      "    log_dir = 'NAIJA.log'\n",
      "    log_level = 'info'\n",
      "    # Start logging\n",
      "    logger = logging.getLogger('NAIJA')\n",
      "    # Set level\n",
      "    if log_level == 'error':\n",
      "        logger.setlevel(logging.ERROR)\n",
      "    # Go\n",
      "    if log_dir:\n",
      "        fh = logging.FileHandler(log_dir, 'a')\n",
      "    else:\n",
      "        fh = logging.FileHandler('backup.log', 'a')\n",
      "    formatter = logging.Formatter('%(levelname)s; %(asctime)s; %(message)s')\n",
      "    fh.setFormatter(formatter)\n",
      "    logger.addHandler(fh)\n",
      "    \n",
      "    '''\n",
      "    Preliminary\n",
      "    '''\n",
      "    \n",
      "    # Check if database exists in given path\n",
      "    dbE = naijadbExists(path, dbname)\n",
      "    if dbE == True and override == 'FALSE':\n",
      "        naijadbSetup(dbname, tablename, path = path, override = override)\n",
      "    else: \n",
      "        print \"Successfully set up the database in directory {} with name {}\".format(path, dbname)\n",
      "        # setup the database\n",
      "        naijadbSetup(dbname, tablename, path = path, override = override)\n",
      "    \n",
      "    '''\n",
      "    Scraping\n",
      "    '''\n",
      "    \n",
      "    # Run naijaPages function\n",
      "    pages = naijaPages(lower_range, upper_range)\n",
      "    # For each page, do . . . \n",
      "    for page in pages:\n",
      "        try:\n",
      "            # Take urls from the index\n",
      "            indUrls = naijaIndex(page)\n",
      "        except:\n",
      "            logger.error(\"INDEX: There was an error while extracting the urls for the individual pages from url {}.\".format(url))\n",
      "        # For each indexed url, do . . . \n",
      "        for url in indUrls:\n",
      "            # Check if URL already in database\n",
      "            res = naijadbCheck(url, dbname, tablename, path = path)\n",
      "            if res != None and override == \"FALSE\":\n",
      "                continue\n",
      "            else:\n",
      "                try:\n",
      "                    vals = naijaReport(url)\n",
      "                    naijadbInsert(vals, dbname, tablename, path = path)\n",
      "                except:\n",
      "                    logger.error('DETAILS: There occurred an error while scraping the details for url {}.'.format(url))\n",
      "\n",
      "'''\n",
      "++++ RUN MAIN ++++\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "'\\n++++ RUN MAIN ++++\\n'"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lower_range = 1 \n",
      "upper_range = 5\n",
      "dbname = \"Naija2015\"\n",
      "tablename = \"naija\"\n",
      "path = \"/users/jasper/desktop/\"\n",
      "override = 'FALSE'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pages = naijaPages(lower_range, upper_range)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indUrls = naijaIndex(pages[1])\n",
      "print indUrls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'http://reclaimnaija.net/reports/view/14760', u'http://reclaimnaija.net/reports/view/14770', u'http://reclaimnaija.net/reports/view/14484', u'http://reclaimnaija.net/reports/view/14470', u'http://reclaimnaija.net/reports/view/14473']\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vals = naijaReport(indUrls[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "GEO: There occurred an error while extracting the geolocations for url http://reclaimnaija.net/reports/view/14760. This isn't absolutely necessary, and the rest of the data should still be collected!\n",
        "COMPLAINT: There occurred an error while scraping the report for url http://reclaimnaija.net/reports/view/14760.\n",
        "DETAILS: There occurred an error while scraping the details for url http://reclaimnaija.net/reports/view/14760.\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "'''\n",
      "Preliminary\n",
      "'''\n",
      "\n",
      "# Check if database exists in given path\n",
      "dbE = naijadbExists(path, dbname)\n",
      "if dbE == True and override == 'FALSE':\n",
      "    naijadbSetup(dbname, tablename, path = path, override = override)\n",
      "else: \n",
      "    print \"Successfully set up the database in directory {} with name {}\".format(path, dbname)\n",
      "    # setup the database\n",
      "    naijadbSetup(dbname, tablename, path = path, override = override)\n",
      "\n",
      "'''\n",
      "Scraping\n",
      "'''\n",
      "\n",
      "# Run naijaPages function\n",
      "pages = naijaPages(lower_range, upper_range)\n",
      "# For each page, do . . . \n",
      "for page in pages:\n",
      "    try:\n",
      "        # Take urls from the index\n",
      "        indUrls = naijaIndex(page)\n",
      "    except:\n",
      "        logger.error(\"INDEX: There was an error while extracting the urls for the individual pages from url {}.\".format(url))\n",
      "    # For each indexed url, do . . . \n",
      "    for url in indUrls:\n",
      "        # Check if URL already in database\n",
      "        res = naijadbCheck(url, dbname, tablename, path = path)\n",
      "        if res != None and override == \"FALSE\":\n",
      "            continue\n",
      "        else:\n",
      "            try:\n",
      "                vals = naijaReport(url)\n",
      "                naijadbInsert(vals, dbname, tablename, path = path)\n",
      "            except:\n",
      "                logger.error('DETAILS: There occurred an error while scraping the details for url {}.'.format(url))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = pages[0]\n",
      "page = requests.get(url).text\n",
      "soup = BeautifulSoup(page, \"html.parser\")\n",
      "# Identify the table which holds the values of interest.\n",
      "table = soup.find('div',{'class':'rb_list-and-map-box table-responsive'})\n",
      "# isolate reports\n",
      "tabsun = table.findAll('div', {'class' : 'rb_report unverified'})\n",
      "tabsve = table.findAll('div', {'class' : 'rb_report verified'})\n",
      "tabs = tabsun + tabsve\n",
      "urls = [ N.find('a').get('href')\n",
      "         for N in tabs ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'http://reclaimnaija.net/reports/view/14718', u'http://reclaimnaija.net/reports/view/14693', u'http://reclaimnaija.net/reports/view/14700', u'http://reclaimnaija.net/reports/view/14639', u'http://reclaimnaija.net/reports/view/14615']\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rep = \"rb_report unverified\"\n",
      "re.findall('rb_report[(\\w)., ]*', string = rep)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "['rb_report unverified']"
       ]
      }
     ],
     "prompt_number": 34
    }
   ],
   "metadata": {}
  }
 ]
}