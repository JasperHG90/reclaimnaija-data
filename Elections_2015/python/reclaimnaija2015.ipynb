{
 "metadata": {
  "name": "",
  "signature": "sha256:62f2fbb16b38797e98973c2d370b20b840e34c19debd5f8180392c8ccc074161"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "\n",
      "This script scrapes information about harrassment at the Nigerian 2015 elections from www.reclamnaija.com \n",
      "Written by : Jasper Ginn \n",
      "Date : 18-04-2015\n",
      "Last modified : 18-04-2015\n",
      "Please send suggestions/comments to : Jasperginn@hotmail.com \n",
      "\n",
      "'''\n",
      "\n",
      "# --------------------------------------------------------------------------------\n",
      "\n",
      "'''\n",
      "Import modules\n",
      "'''\n",
      "\n",
      "# Import os\n",
      "import os\n",
      "# BeautifulSoup\n",
      "from bs4 import BeautifulSoup\n",
      "# Logging\n",
      "import logging\n",
      "# requests\n",
      "import requests\n",
      "# Import SQLite\n",
      "import sqlite3 as lite\n",
      "# Import regex\n",
      "import re\n",
      "# Import datetime\n",
      "import datetime\n",
      "# Import os.path (to check if db exists)\n",
      "import os.path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "+++ MAIN FUNCTIONS +++\n",
      "'''\n",
      "\n",
      "'''\n",
      "FUNCTION 1 : function that captures the index of all urls on each page\n",
      "    parameters : \n",
      "        url  :  string\n",
      "            url of the index page.\n",
      "'''\n",
      "\n",
      "def naijaIndex(url):\n",
      "    page = requests.get(url).text\n",
      "    soup = BeautifulSoup(page, \"html.parser\")\n",
      "    # Identify the table which holds the values of interest.\n",
      "    # Identify the table which holds the values of interest.\n",
      "    table = soup.find('div',{'class':'rb_list-and-map-box table-responsive'})\n",
      "    # isolate reports\n",
      "    tabsun = table.findAll('div', {'class' : 'rb_report unverified'})\n",
      "    tabsve = table.findAll('div', {'class' : 'rb_report verified'})\n",
      "    tabs = tabsun + tabsve\n",
      "    urls = [ N.find('a').get('href')\n",
      "             for N in tabs ]\n",
      "    # Return\n",
      "    return(urls)\n",
      "        \n",
      "'''\n",
      "FUNCTION 2 : Function that scrapes results from each individual page and stores it in the database. [Note: This is not the prettiest\n",
      "             Function, but it does the job.]\n",
      "    parameters : \n",
      "        url  :  string\n",
      "            url pointing towards the individual report\n",
      "'''\n",
      "\n",
      "def naijaReport(url):\n",
      "    soup = BeautifulSoup(requests.get(url).text)\n",
      "    # Lon / Lat\n",
      "    try:\n",
      "        geo = naijaLocs(soup)\n",
      "        lon = geo[0]\n",
      "        lat = geo[1]\n",
      "    except:\n",
      "        print(\"GEO: There occurred an error while extracting the geolocations for url {}. This isn't absolutely necessary, and the rest of the data should still be collected!\".format(url))\n",
      "        lon = \"\"\n",
      "        lat = \"\"\n",
      "    try:\n",
      "        # report\n",
      "        text = soup.find('div',{'class':'report-description-text'}).contents[2].replace(\"\\n\\t\\t\\t\", \"\").strip(\"\\t\")\n",
      "    except: \n",
      "        print(\"COMPLAINT: There occurred an error while scraping the report for url {}.\".format(url))\n",
      "        text = \"\"\n",
      "    try:\n",
      "        # Details\n",
      "        reportD = soup.find('div',{'class':'report_detail'})\n",
      "        # Verified?\n",
      "        ver = reportD.find('p', {\"class\":\"r_unverified\"}).text\n",
      "        # tag\n",
      "        tag = reportD.find('h1', {\"class\":\"report-title heading\"}).text\n",
      "        # Details\n",
      "        Loc = reportD.find(\"span\", {\"class\":\"r_location\"}).text\n",
      "        dttime = reportD.find(\"span\", {\"class\":\"r_date\"}).text.split()\n",
      "        Dat = datetime.datetime.strptime(' '.join(dttime[1:len(dttime)]),'%b %d %Y').date()\n",
      "        Tim = dttime[0]\n",
      "        Cat = reportD.find(\"div\", {\"class\":\"report-category-list\"}).find(\"a\").get(\"title\")\n",
      "        scrapedate = datetime.date.today()\n",
      "    except:\n",
      "        print 'DETAILS: There occurred an error while scraping the details for url {}.'.format(url)\n",
      "        ver = \"\"\n",
      "        tag = \"\"\n",
      "        Loc = \"\"\n",
      "        Dat = \"\"\n",
      "        Tim = \"\"\n",
      "        Cat = \"\"\n",
      "        scrapedate = datetime.date.today()\n",
      "    # Insert values in db\n",
      "    vals = [ ( url ,\n",
      "             str(Dat) ,\n",
      "             Loc ,\n",
      "             lon ,\n",
      "             lat ,\n",
      "             tag , \n",
      "             text ,\n",
      "             ver ,\n",
      "             Cat ,\n",
      "             str(Tim) ,\n",
      "             str(scrapedate) ) ]\n",
      "    # Return\n",
      "    return(vals)\n",
      "\n",
      "'''\n",
      "+++ HELPER FUNCTIONS +++\n",
      "'''\n",
      "\n",
      "'''\n",
      "FUNCTION 3 : create the URLs for the scraper\n",
      "    Parameters : \n",
      "        lower_range : integer\n",
      "            Low end of the page number (lower == more recent). Should be set at 1\n",
      "        upper_range : integer\n",
      "            High end of the page number (higher == less recent).\n",
      "'''\n",
      "\n",
      "def naijaPages(lower_range, upper_range):\n",
      "    pages = range(lower_range,upper_range)\n",
      "    urls = [ 'http://reclaimnaija.net/reports?page={}'.format(str(p)) \n",
      "             for p in pages ]\n",
      "    return(urls)\n",
      "\n",
      "'''\n",
      "FUNCTION 4 : create the SQLite database and commit headers\n",
      "    Parameters :\n",
      "        dbname    : string\n",
      "            name of the database\n",
      "        tablename : string\n",
      "            name of the table in which to store results\n",
      "        path  : string\n",
      "            path to store database. Defaults to '/home/vagrant/Documents/'\n",
      "'''\n",
      "\n",
      "def naijadbSetup(dbname, tablename, path = '~/desktop', override = \"TRUE\"):\n",
      "    # Want to replace the database?\n",
      "    if override == 'TRUE':\n",
      "        pathfile = naijaPathmaker(dbname, path)\n",
      "        con = lite.connect(pathfile)\n",
      "        cur = con.cursor()\n",
      "        # send headers and create table\n",
      "        cur.execute(\"DROP TABLE IF EXISTS {};\".format(tablename))\n",
      "        cur.execute(\"CREATE TABLE {}(URL TEXT, Date TEXT, Location TEXT, Longitude REAL, Latitude REAL, Title TEXT, Report TEXT, Verified TEXT, Category TEXT, Time TEXT, Scrapedate TEXT)\".format(tablename))\n",
      "        # Commit\n",
      "        con.commit()\n",
      "    else:\n",
      "        print \"A database with the name {} already exists for path {}. You specified the override option to be {}. The database will be left alone . . . yay!\".format(dbname, path, str(override))\n",
      "\n",
      "'''\n",
      "FUNCTION 5 : Insert results form each page to the database\n",
      "    Parameters :\n",
      "        values_list : list \n",
      "            list of values to send to the database\n",
      "        dbname      : string\n",
      "            name of the database\n",
      "        tablename   : string\n",
      "            name of the table in which to store results\n",
      "        path        : string\n",
      "            path to the database. Defaults to '/home/vagrant/Documents/'\n",
      "'''\n",
      "\n",
      "def naijadbInsert(values_list, dbname, tablename , path = '~/desktop/'):\n",
      "    pathfile = naijaPathmaker(dbname, path)\n",
      "    try:\n",
      "        con = lite.connect(pathfile) \n",
      "        with con:  \n",
      "            # Cursor file\n",
      "            cur = con.cursor()\n",
      "            # Write values to db\n",
      "            cur.executemany(\"INSERT INTO {} (URL, Date, Location, Longitude, Latitude, Title, Report, Verified, Category, Time , Scrapedate) VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?);\".format(tablename), values_list)\n",
      "            # Commit (i.e. save) changes\n",
      "            con.commit()\n",
      "        # Close connection\n",
      "        con.close()           \n",
      "    except:\n",
      "        print 'Error while setting up the database. Quitting the script now . . . '\n",
      "        \n",
      "'''\n",
      "FUNCTION 7 : Helper function to retrieve longitude and latitude \n",
      "    parameters :\n",
      "        soup_object  :  A BeautifulSoup instance\n",
      "            Soup object from the report url\n",
      "'''\n",
      "\n",
      "def naijaLocs(soup_object):\n",
      "    # Found the Lon/Lat combination. Not pretty, but oh well . . . \n",
      "    lon = re.findall('longitude: [(\\d)., ]*', string = soup_object.text)[0].strip('longitude: ')\n",
      "    lat = re.findall('latitude: [(\\d)., ]*', string=soup_object.text)[0].strip('latitude: ').strip(',')\n",
      "    return(float(lon), float(lat))\n",
      "\n",
      "'''\n",
      "FUNCTION 8 : Helper function to check if the database already exists. If exists, then don't make a new one (unless you specified to overwrite the database)\n",
      "    parameters :\n",
      "        path : string\n",
      "            path to the database\n",
      "        tablename : string\n",
      "            name of the SQLite database\n",
      "        \n",
      "'''\n",
      "\n",
      "def naijadbExists(path, dbname):\n",
      "    if path.endswith('/'):\n",
      "        ret = os.path.isfile(path + dbname) \n",
      "        return(ret)\n",
      "    else:\n",
      "        ret = os.path.isfile(path + '/' + dbname)\n",
      "        return(ret)\n",
      "    \n",
      "'''\n",
      "FUNCTION 9 : Helper function to check whether a report already exists in the database. Here, we are checking the specific report URL\n",
      "(which is basically a unique ID) against all report URLs that already exist in the db.\n",
      "    parameters : \n",
      "        url : string\n",
      "            url of the specific report at reclaimnaija\n",
      "        dbname : string\n",
      "            name of the database\n",
      "        dbtable : string\n",
      "            table in which reclaimnaija results are stored\n",
      "        path : string\n",
      "            system path where the database is stored. Defaults to '~/desktop'\n",
      "'''\n",
      "\n",
      "def naijadbCheck(url, dbname, dbtable, path = '~/desktop/'):\n",
      "    pathsal = naijaPathmaker(dbname, path)\n",
      "    con = lite.connect(pathsal)\n",
      "    # Cursor file\n",
      "    with con:\n",
      "        cur = con.cursor()\n",
      "        cur.execute(\"SELECT URL FROM {} WHERE URL = ?\".format(dbtable), (url,))\n",
      "        data=cur.fetchone()\n",
      "        if data is None:\n",
      "            return(None)\n",
      "        else:\n",
      "            print('Report for url {} already in database . . . moving on'.format(url))\n",
      "            return(data[0])\n",
      "    # Close db connection\n",
      "    con.close()\n",
      "    \n",
      "'''\n",
      "FUNCTION 10 : Helper function that creates the path for the database. It evaluates whether the path specified by the user ends with\n",
      "'/'. If yes, then paste. If no, then add the '/' to avoid problems.\n",
      "    parameters :\n",
      "        dbname : string\n",
      "            name of the database\n",
      "        path : string\n",
      "            system path where the database is stored. Defaults to '~/desktop'\n",
      "'''\n",
      "\n",
      "def naijaPathmaker(dbname, path):\n",
      "    if path.endswith('/'):\n",
      "        return(path + dbname + '.db')\n",
      "    else:\n",
      "        return(path + '/' + dbname + '.db')\n",
      "\n",
      "'''\n",
      "+++ MAIN +++\n",
      "'''\n",
      "\n",
      "def main(lower_range, upper_range, dbname, tablename, path = \"~/desktop/\", override = 'FALSE'):\n",
      "    \n",
      "    '''\n",
      "    Set up logger\n",
      "    '''\n",
      "    \n",
      "    # Log name\n",
      "    log_dir = 'NAIJA.log'\n",
      "    log_level = 'info'\n",
      "    # Start logging\n",
      "    logger = logging.getLogger('NAIJA')\n",
      "    # Set level\n",
      "    if log_level == 'error':\n",
      "        logger.setlevel(logging.ERROR)\n",
      "    # Go\n",
      "    if log_dir:\n",
      "        fh = logging.FileHandler(log_dir, 'a')\n",
      "    else:\n",
      "        fh = logging.FileHandler('backup.log', 'a')\n",
      "    formatter = logging.Formatter('%(levelname)s; %(asctime)s; %(message)s')\n",
      "    fh.setFormatter(formatter)\n",
      "    logger.addHandler(fh)\n",
      "    \n",
      "    '''\n",
      "    Preliminary\n",
      "    '''\n",
      "    \n",
      "    # Check if database exists in given path\n",
      "    dbE = naijadbExists(path, dbname)\n",
      "    if dbE == True and override == 'FALSE':\n",
      "        naijadbSetup(dbname, tablename, path = path, override = override)\n",
      "    else: \n",
      "        print \"Successfully set up the database in directory {} with name {}\".format(path, dbname)\n",
      "        # setup the database\n",
      "        naijadbSetup(dbname, tablename, path = path, override = override)\n",
      "    \n",
      "    '''\n",
      "    Scraping\n",
      "    '''\n",
      "    \n",
      "    # Run naijaPages function\n",
      "    pages = naijaPages(lower_range, upper_range)\n",
      "    # For each page, do . . . \n",
      "    for page in pages:\n",
      "        try:\n",
      "            # Take urls from the index\n",
      "            indUrls = naijaIndex(page)\n",
      "        except:\n",
      "            logger.error(\"INDEX: There was an error while extracting the urls for the individual pages from url {}.\".format(url))\n",
      "        # For each indexed url, do . . . \n",
      "        for url in indUrls:\n",
      "            # Check if URL already in database\n",
      "            res = naijadbCheck(url, dbname, tablename, path = path)\n",
      "            if res != None and override == \"FALSE\":\n",
      "                continue\n",
      "            else:\n",
      "                try:\n",
      "                    vals = naijaReport(url)\n",
      "                    naijadbInsert(vals, dbname, tablename, path = path)\n",
      "                except:\n",
      "                    logger.error('DETAILS: There occurred an error while scraping the details for url {}.'.format(url))\n",
      "\n",
      "'''\n",
      "++++ RUN MAIN ++++\n",
      "'''\n",
      "\n",
      "main(1,2995, 'NAIJA_sec', 'NAIJA_tab', path = '/users/jasper/documents/github.projects/reclaimnaija/Elections_2015/data/', override = 'FALSE')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Successfully set up the database in directory /users/jasper/documents/github.projects/reclaimnaija/Elections_2015/data/ with name NAIJA_sec\n",
        "A database with the name NAIJA_sec already exists for path /users/jasper/documents/github.projects/reclaimnaija/Elections_2015/data/. You specified the override option to be FALSE. The database will be left alone . . . yay!\n",
        "Report for url http://reclaimnaija.net/reports/view/14718 already in database . . . moving on"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Report for url http://reclaimnaija.net/reports/view/14693 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14700 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14639 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14615 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14760 already in database . . . moving on"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Report for url http://reclaimnaija.net/reports/view/14770 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14484 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14470 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14473 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14459 already in database . . . moving on"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Report for url http://reclaimnaija.net/reports/view/14464 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14443 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14447 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14492 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14494 already in database . . . moving on"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Report for url http://reclaimnaija.net/reports/view/14512 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14524 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14779 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14596 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14547 already in database . . . moving on"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Report for url http://reclaimnaija.net/reports/view/14668 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14740 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14796 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14557 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14572 already in database . . . moving on"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Report for url http://reclaimnaija.net/reports/view/14584 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14605 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14629 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14804 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14813 already in database . . . moving on"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Report for url http://reclaimnaija.net/reports/view/14829 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14838 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14852 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14860 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14865 already in database . . . moving on"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Report for url http://reclaimnaija.net/reports/view/14424 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14428 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14869 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14885 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14307 already in database . . . moving on"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Report for url http://reclaimnaija.net/reports/view/14311 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14313 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14309 already in database . . . moving on\n",
        "Report for url http://reclaimnaija.net/reports/view/14315 already in database . . . moving on\n"
       ]
      }
     ],
     "prompt_number": 85
    }
   ],
   "metadata": {}
  }
 ]
}